{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rEwt5wWvjtt5"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def tokenize(text):\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text)\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pair_frequencies(corpus):\n",
        "    pairs = {}\n",
        "    for word in corpus:\n",
        "        symbols = word.split()\n",
        "        for i in range(len(symbols) - 1):\n",
        "            pair = (symbols[i], symbols[i + 1])\n",
        "            if pair in pairs:\n",
        "                pairs[pair] += 1\n",
        "            else:\n",
        "                pairs[pair] = 1\n",
        "    return pairs\n",
        "\n",
        "def merge_pair(corpus, pair):\n",
        "    merged_corpus = []\n",
        "    bigram = ' '.join(pair)\n",
        "    replacement = ''.join(pair)\n",
        "\n",
        "    for word in corpus:\n",
        "        new_word = word.replace(bigram, replacement)\n",
        "        merged_corpus.append(new_word)\n",
        "    return merged_corpus\n",
        "\n",
        "def bpe(corpus, num_iterations):\n",
        "    corpus = [' '.join(list(word)) for word in corpus]\n",
        "    vocab = set(' '.join(corpus).split())\n",
        "    vocab = list(vocab)\n",
        "\n",
        "    for _ in range(num_iterations):\n",
        "        pair_frequencies = get_pair_frequencies(corpus)\n",
        "        if not pair_frequencies:\n",
        "            break\n",
        "\n",
        "        most_frequent_pair = max(pair_frequencies, key=pair_frequencies.get)\n",
        "\n",
        "        corpus = merge_pair(corpus, most_frequent_pair)\n",
        "\n",
        "        vocab.append(''.join(most_frequent_pair))\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "ooFQ7oihFIHB"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def levenshtein_distance(s1, s2, m, n):\n",
        "    if m == 0:\n",
        "        return n\n",
        "\n",
        "    if n == 0:\n",
        "        return m\n",
        "\n",
        "    if s1[m - 1] == s2[n - 1]:\n",
        "        return levenshtein_distance(s1, s2, m - 1, n - 1)\n",
        "\n",
        "    return 1 + min(levenshtein_distance(s1, s2, m, n - 1),\n",
        "                   levenshtein_distance(s1, s2, m - 1, n),\n",
        "                   levenshtein_distance(s1, s2, m - 1, n - 1))\n",
        "def editDist(s1, s2):\n",
        "    return levenshtein_distance(s1, s2, len(s1), len(s2))"
      ],
      "metadata": {
        "id": "ntVpA6TqKoUj"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline(text):\n",
        "    tokens = tokenize(text)\n",
        "    vocab = bpe(tokens,5)\n",
        "    return tokens, vocab"
      ],
      "metadata": {
        "id": "6fuETmi2NZO4"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"London is the capital and most populous city of England and the United Kingdom.\"\n",
        "print(pipeline(text))\n",
        "print(editDist(\"London\", \"Londinium\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwHm64XOjug1",
        "outputId": "9bbddc3f-4d20-47dc-8759-f3b6bc70f42e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['London', 'is', 'the', 'capital', 'and', 'most', 'populous', 'city', 'of', 'England', 'and', 'the', 'United', 'Kingdom', '.'], ['.', 'n', 'U', 'i', 'l', 'u', 't', 'o', 'd', 'g', 'm', 'p', 'c', 'E', 'a', 's', 'L', 'h', 'e', 'K', 'f', 'y', 'nd', 'it', 'and', 'th', 'the'])\n",
            "4\n"
          ]
        }
      ]
    }
  ]
}